{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a39bba82",
   "metadata": {},
   "source": [
    "## <center> Assignment 3 </center>\n",
    "\n",
    "#### Name: Aditya Chauhan\n",
    "#### Student ID: 169027493\n",
    "\n",
    "You are provided with a training dataset and a testing dataset for a binary classification problem with labels {0, 1}. The last column of the training dataset contains the labels, while the testing dataset includes only attributes (descriptive features).\n",
    "\n",
    "Train an effective classifier using the training dataset. You may choose your data processing approach, classifier type, and parameter tuning methods as needed. The sklearn package in Python is recommended for implementing your model.\n",
    "\n",
    "Make predictions on the testing dataset and generate a file containing a single column of predicted labels (0 or 1) in the same order as the testing dataset. Ensure that the output file does not include a header and that your prediction.txt file contains exactly one column and 352 rows.\n",
    "\n",
    "Please submit your implementation code and the predicted output file as two separate files (not compressed into a zip file), named <b>A3.ipynb</b> and <b>prediction.txt</b>, respectively. Your assignment will be evaluated based on your model's performance, particularly its F1-score, as well as other criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2002f4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv('A3_data/train.csv',sep=',',index_col=0) \n",
    "df_test_attribute_only = pd.read_csv('A3_data/test_attribute.csv',sep=',',index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b2a48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 652 entries, 0 to 651\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       652 non-null    float64\n",
      " 1   1       652 non-null    float64\n",
      " 2   2       652 non-null    float64\n",
      " 3   3       652 non-null    float64\n",
      " 4   4       652 non-null    float64\n",
      " 5   5       652 non-null    float64\n",
      " 6   6       652 non-null    float64\n",
      " 7   7       652 non-null    float64\n",
      " 8   8       652 non-null    int64  \n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 50.9 KB\n",
      "None\n",
      "\n",
      "Test Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 352 entries, 0 to 351\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       352 non-null    float64\n",
      " 1   1       352 non-null    float64\n",
      " 2   2       352 non-null    float64\n",
      " 3   3       352 non-null    float64\n",
      " 4   4       352 non-null    float64\n",
      " 5   5       352 non-null    float64\n",
      " 6   6       352 non-null    float64\n",
      " 7   7       352 non-null    float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 24.8 KB\n",
      "None\n",
      "\n",
      "Train Dataset Head:\n",
      "      0     1     2     3    4    5     6     7  8\n",
      "0  0.81  0.85  0.47  0.37  0.5  0.0  0.56  0.22  1\n",
      "1  0.70  0.58  0.53  0.39  0.5  0.0  0.59  0.22  1\n",
      "2  0.72  0.73  0.41  0.28  0.5  0.0  0.44  0.22  1\n",
      "3  0.78  0.69  0.44  0.26  0.5  0.0  0.54  0.22  1\n",
      "4  0.74  0.82  0.46  0.24  0.5  0.0  0.48  0.22  1\n",
      "\n",
      "Test Dataset Head:\n",
      "      0     1     2     3    4     5     6     7\n",
      "0  0.74  0.72  0.50  0.28  0.5  0.00  0.49  0.27\n",
      "1  0.80  0.88  0.36  0.39  0.5  0.00  0.56  0.33\n",
      "2  0.57  0.52  0.46  0.20  0.5  0.83  0.52  0.41\n",
      "3  0.77  0.82  0.40  0.36  0.5  0.00  0.38  0.22\n",
      "4  0.69  0.60  0.51  0.13  0.5  0.83  0.52  0.22\n",
      "\n",
      "Missing Values in Train Dataset:\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Test Dataset:\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "dtype: int64\n",
      "\n",
      "F1 Score on Validation Set: 0.8571428571428571\n",
      "\n",
      "Predictions saved to prediction.txt\n"
     ]
    }
   ],
   "source": [
    "## your code here\n",
    "\n",
    "# Data Exploration\n",
    "\n",
    "print(\"Train Dataset Info:\")\n",
    "print(df_train.info())\n",
    "print(\"\\nTest Dataset Info:\")\n",
    "print(df_test_attribute_only.info())\n",
    "\n",
    "print(\"\\nTrain Dataset Head:\")\n",
    "print(df_train.head())\n",
    "\n",
    "print(\"\\nTest Dataset Head:\")\n",
    "print(df_test_attribute_only.head())\n",
    "\n",
    "# Separate features and target from the training data\n",
    "\n",
    "X_train = df_train.iloc[:, :-1]  # All columns except the last one\n",
    "y_train = df_train.iloc[:, -1]   # The last column\n",
    "\n",
    "# Check for missing values\n",
    "\n",
    "print(\"\\nMissing Values in Train Dataset:\")\n",
    "print(df_train.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing Values in Test Dataset:\")\n",
    "print(df_test_attribute_only.isnull().sum())\n",
    "\n",
    "# Preprocess the data\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Handle any missing values\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(df_test_attribute_only)\n",
    "\n",
    "# Standardize the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train the Model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Split data for validation\n",
    "\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Validate the model & Predict on test data\n",
    "\n",
    "y_val_pred = clf.predict(X_val)\n",
    "print(\"\\nF1 Score on Validation Set:\", f1_score(y_val, y_val_pred))\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# Save Predictions to File\n",
    "\n",
    "output_file = 'prediction.txt'\n",
    "with open(output_file, 'w') as f:\n",
    "    for label in y_test_pred:\n",
    "        f.write(f\"{label}\\n\")\n",
    "\n",
    "print(f\"\\nPredictions saved to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea59e06",
   "metadata": {},
   "source": [
    "### Briefly describe your approach in the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c942ae",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
